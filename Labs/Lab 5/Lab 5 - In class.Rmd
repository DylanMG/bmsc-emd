---
title: "Lab 5: Hierarchical models and derived parameters"
output: html_document
date: "2023-06-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
library(nlme)
library(stats4)
library(ggplot2)
```

## What are fixed and random effects

*Fixed Effects* are parameters associated with the entire population or with certain repeatable levels of experimental units. - For example, what is the expected body size of a yelloweye rockfish.

*Random Effects* are parameters associated with individual experimental units drawn at random from a population.
- For example, what is the expected body size of the 23rd population of yelloweye rockfish, as chosen from a database.

A mixed effects model is a model that has both *fixed effects* and *random effects*. Often the same random effect is assigned to observations sharing a common grouping factor (or other classifying factor). Consider length-at-age data for several (randomly selected) populations of a species. A random factor could be stock and the observations are length-at-age data. Random effects can the thought of as ways of modelling the covariance structure of the data.

Classical (frequentist) and Bayesian methods can be used to estimate the parameters of mixed effects models. This lab and homework will cover Frequentist. Lab 6 will cover their implementation in Stan.

```{r read the data}
Streams <- readRDS(file="Data/streams.rds")
colnames(Streams) <- c("Stream","true_density","Density")
```

## Including Plots

```{r lm version 1, echo=FALSE}
 print("Linear Fixed Effects Model")
 lm1 <- lm(Density~1,data=Streams)
 boxplot(split(lm1$residuals,Streams$Stream),ylab="Residual",xlab="Stream",csi=0.2)
 abline(0,0,lwd=3)
 print(summary(lm1))
 print(paste("AIC ",AIC(lm1)))
```

This analysis attributed all the error to within-stream variation. However, it is clear that there is between-stream variation in density but we have no way to make any inference or insight on it. 

Let's see if we can ask if streams vary instead?
```{r lm version 2, echo=FALSE}
print("Linear Fixed Effects Model, with stream-effect") 
lm2 <- lm(Density~Stream-1,data=Streams)   
 boxplot(split(lm2$residuals,Streams$Stream),ylab="Residual",xlab="Stream",csi=0.2)
 abline(0,0,lwd=3)
 print(summary(lm2))
 print(paste("AIC ",AIC(lm2)))
```

Well, good news. The residual pattern has been removed, but we have no overall mean and no way to comment on between-stream variance, i.e. we cannot say anything about the population of streams

```{r lme, echo=FALSE}
 lm3 <- lme(fixed = Density ~ 1,data=Streams,random = ~ 1 | Stream) 
 boxplot(split(lm3$residuals,Streams$Stream),ylab="Residual",xlab="Stream",csi=0.2)
 abline(0,0,lwd=3)
 print(summary(lm3))
```
Now, we've taken care of the strong patterning in the residuals and we can now comment on an overall mean and between-stream variance. What are the estimates of the stream-specifics?

```{r extract randome effects}
plot(as.numeric(unique(Streams$true_density)),coef(lm3)[[1]],xlab="True value",ylab="Random effects") # extract the stream-level effects (fixed effect + random effects) and compare to true values
abline(b=1,a=0) # add a 1:1 line for comparison
```

### Hierarchical model: what's under the hood
We are going to construct a numerical algorithm, using Simpson's 1/3 rule, to approximate the integral of the random effects conditional on the maximum likelihood estimate. To do this, we will:
- create a 1st function that calculates the likelihood inside the integral
- create a 2nd function that applies the Simpson's Rule that to function 1 to look over possibles values of the random effects $b_i$, from -5 to 5 and calls *function 1*
- create a 3rd function that provides the joint likelihood for the model and calls *function 2*
- create a 4th function that maximizes the likelihood, using the `mle()` function in R that calls *function 3*.

```{r calculate likelihood inside the integral, echo=FALSE}
norm.lik = function(bi,sig_e,sig_b,beta,stream)
{
  nobs<-3 #number of observations per stream
  lik.a<-lik.fix<-rep(NA,nobs)
  dat<-subset(Streams,Streams$Stream==stream) # subset the data to the group in question
  lik.random<-1/sqrt(2*pi)*exp(-(bi^2)/2) # Question: what does this statement imply?
  for(k in 1:nobs)
  {
    lik.fix[k]<-1/sqrt(2*pi*sig_e^2)*exp(-((dat$Density[k]-beta-bi*sig_b)^2)/(2*sig_e^2)) # likelihood, conditional on fixed effects plus 
  }
  lik.fix.a<-prod(lik.fix) # remember: joint likelihoods are the PRODUCT of all likelihoods (or, alternatively, the joint log-likelihood is the SUM of all log-likelihoods)
  lik.a<-lik.random*lik.fix.a # total likelihood of this slice of the integral is the product of the fixed effect and the random effect likelihoods
  return(lik.a)
}
```

Here is *Function 2*, which applies Simpson's 1/3 Rule and calls *Function 1*.

```{r apply simpsons rule in function 2}
simpson  <-  function(lowerb, upperb, nbins, stream,beta, sig_e, sig_b) 
{
  step <- (upperb-lowerb)/nbins
  b_vec <- seq(lowerb, upperb, by=step)
  frac_vec <- c(1/3, rep(c(4/3, 2/3), times=((nbins+1)-3)/2), 4/3, 1/3)
  sum_comp <- vector(length=length(b_vec))
  for(i in 1:length(b_vec)){
    sum_comp[i] <- frac_vec[i]*norm.lik(bi=b_vec[i], sig_e=sig_e, sig_b=sig_b, beta=beta, stream=stream)
  }
  full_like <- sum(sum_comp)*step
  return(full_like)
}
```
We should be somewhat comfortable with the below function: we pass some parameters to a function and call *Function 2* (which calls *Function 1*) to calculate the joint likelihood.
```{r likelihood}
loglike=function(l_sig_e,l_sig_b,beta)
{
  sig_e <- exp(l_sig_e)
  sig_b<-exp(l_sig_b)
  stream <- c(1,2,3,4,5,6)
  like.str <- vector(length=length(stream))
  for (i in stream)
  {
    like.str[i] <- simpson(lowerb=lowerb, upperb=upperb, nbins=nbins, sig_e=sig_e, sig_b=sig_b, beta=beta, stream=stream[i])
  }
  nll <- (-1)*sum(log(like.str))
  return(nll)
}
```

Now let's optimize! Rather than `optim()` we will use a similar package called `mle`, which automatically provides some standard errors based on the Hessian matrix from Lab 2. Note that `mle()` is a function, which calls `loglike()`, which calls `simpson()`, which calls `norm.lik()`. It's why hierarchical models are complicated!

Below, we will the number of bins for our integral and the lower- and upper-bounds to integrate across.
```{r MLE fit}
lowerb <- -5 # the lower bound of the integral
upperb <- 5 # the upper bound of the integral
nbins <- 100 # the number of bins (or the step-size) of the integral
fit1=mle(loglike,start=list(l_sig_e=log(10),l_sig_b=log(10),beta=70),nobs=length(Streams$Density),method="BFGS")
summary(fit1)
l_sig_e=coef(fit1)[[1]]
l_sig_b=coef(fit1)[[2]]
sig_e=exp(coef(fit1)[[1]])
sig_b=exp(coef(fit1)[[2]])
beta=coef(fit1)[[3]]
AIC(fit1)
(-1)*logLik(fit1)[1] # the -1 converts to the negative log likelihood

```

Can you compare this to the estimates from `lme()` or `lme4()`?
```{r compare to to lme}
summary(fit1)
summary(lm3)
```
Next, let's use likelihood profiling - very similar to the Grid Approximation in Lab 2, but applied to Maximum Likelihood Estimation rather than Bayesian inference. To do this, we set up a sequence of possible parameters (in our case, $\beta$ - the group-level mean density among streams) from which to calculate log-likelihoods from (conditional on the updated ML estimates of the *other* parameters)

We will re-arrange our functions accordingly.

Confidence intervals from likelihood profiling are based on the log-likelihood function.  For a given parameter, likelihood theory shows that the two furthest points along a sequence of the parameter that are within 1.92 units of the maximum of the log-likelihood function provide a 95% confidence interval when there is no extrabinomial variation (i.e. c = 1). The value 1.92 is half of the chi-square value of 3.84 with 1 degree of freedom. Thus, the same confidence interval can also be calculated from the deviance by adding 3.84 to the minimum of the deviance function (where the deviance is the log-likelihood multiplied by -2 minus the -2 log likelihood value of the maxmum likelihood model).

Below is a likelihood profile of the beta parameter (based on a search along $\beta_{MLE}\pm0.75\beta_{MLE}$ constructed for the numerical computation of a mixed-effects model of the Streams dataset. This function calculates the negative log-likelihood was profiled across fixed values for beta to assess the 95% confidence intervals, calculated as the minimum and maximum values of β for which $ln\mathcal{L}(\theta|\beta_i )\ge(ln\mathcal{L}(\theta|\beta_{MLE})-1.92)$. The 95% CI from likelihood profiling are compared to the 95% CI calculated from the ‘LME’ package using the function ‘intervals’ in Program R.

```{r profile}
b.profile=seq(from=beta-0.75*beta,to=beta+0.75*beta,length=1000)
theta=c(beta,sig_e,sig_b)
b.pro.fun = function (theta) #(theta)
{
  beta=b.pro
  sig_e=sig_e
  sig_b=sig_b
  lowerb=-5
  upperb=5
  nbins=100
  stream=c(1,2,3,4,5,6)
  like.str=vector(length=length(stream))
  for (i in stream)
  {
    like.str[i]=simpson(lowerb=lowerb, upperb=upperb, nbins=nbins, 
                        sig_e=sig_e, sig_b=sig_b, beta=beta, stream=stream[i])
  }
  nll=(-1)*sum(log(like.str))
  return(nll)
}

beta.loglik=rep(NA,length(b.profile))
for(i in 1:length(b.profile))
{
  b.pro=b.profile[i]
  fit.pro=optim(theta,b.pro.fun,method="BFGS",control=list(maxit=1000))
  beta.loglik[i]=fit.pro$value
}
df=data.frame("b.profile"=b.profile,"log-like"=beta.loglik)
plot(b.profile,beta.loglik,type="l",lty=1,lwd=2,col="black",ylab="Negative Log-Likelihood",xlab="Beta")
abline(v=df[,1][which(df[,2]==min(df[,2]))],col="red",lty=1)
x <- which((-1)*beta.loglik>=logLik(fit1)[1]-1.92) # where is the 
print(range(x)) # here are the minimum/maximum estimates of beta within the 95% CI
print(intervals(lm3))
abline(v=df[min(x),1],col="red",lty=2) #printing x and finding the minimum TRUE row number
abline(v=df[max(x),1],col="red",lty=2) #printing x and finding the maximum TRUE row number
abline(v=64.241,col="darkgreen",lty=3) #taken from the LME fits below
abline(v=93.016,col="darkgreen",lty=3) #taken from the LME fits below
legend("topright",c("ML Beta Value","Profile 95% CI","LME 95% CI"),col=c("red","red","darkgreen"),lty=c(1,2,3))
```